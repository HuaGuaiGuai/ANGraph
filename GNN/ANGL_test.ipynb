{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ANGL import GNN\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import operator\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from functools import reduce\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from evaluate import Evaluator\n",
    "from dataset_handcraft_pyg import PygGraphPropPredDataset\n",
    "\n",
    "reg_criterion = torch.nn.HuberLoss(delta=5)\n",
    "cls_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def eval_mape(pred, target):\n",
    "    mape = 0\n",
    "    for i in range(len(pred)):\n",
    "        mape += np.abs((pred[i]-target[i])/target[i])\n",
    "    return mape/len(pred)\n",
    "\n",
    "def eval_rmse(pred, target):\n",
    "    rmse = 0\n",
    "    for i in range(len(pred)):\n",
    "        rmse += (pred[i]-target[i])**2\n",
    "    rmse = np.sqrt(rmse/len(pred))\n",
    "    return rmse\n",
    "def eval_smape(pred, target):\n",
    "    smape = 0\n",
    "    for i in range(len(pred)):\n",
    "        smape += np.abs(pred[i]-target[i])/((np.abs(pred[i])+np.abs(target[i]))/2)\n",
    "    smape /= len(pred)\n",
    "    return smape\n",
    "\n",
    "def eval_r2(pred, target):\n",
    "    son = 0\n",
    "    mother = 0\n",
    "    miu = np.mean(target)\n",
    "    for i in range(len(pred)):\n",
    "        son += (pred[i]-target[i])**2\n",
    "        mother += (target[i]-miu)**2\n",
    "    r2 = 1 - son/mother\n",
    "    return r2\n",
    "\n",
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)\n",
    "        y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "    # for i in range(len(y_pred)):\n",
    "    #     y_pred[i] *= 1000\n",
    "    #     y_true[i] *= 1000\n",
    "    mape = eval_mape(y_pred, y_true)\n",
    "    print(\"mape:{}\".format(mape))\n",
    "    rmse = eval_rmse(y_pred, y_true)\n",
    "    print(\"mse:{}\".format(rmse))\n",
    "    smape = eval_smape(y_pred, y_true)\n",
    "    print(\"smape:{}\".format(smape))\n",
    "    r2 = eval_r2(y_pred, y_true)\n",
    "    print(\"r2:{}\".format(r2))\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict), y_true, y_pred\n",
    "\n",
    "\n",
    "def eval_norm(model, device, loader, evaluator, min, max):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch)\n",
    "        y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] /= 100\n",
    "        y_pred[i] = (y_pred[i])*(max-min)+ min\n",
    "        y_true[i] /= 100\n",
    "        y_true[i] = (y_true[i])*(max-min)+ min\n",
    "    mape = eval_mape(y_pred, y_true)\n",
    "    print(\"mape:{}\".format(mape))\n",
    "    rmse = eval_rmse(y_pred, y_true)\n",
    "    print(\"mse:{}\".format(rmse))\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict), y_true, y_pred\n"
   ],
   "id": "d14cc00bc6fc4231"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T13:51:39.030084Z",
     "start_time": "2025-01-22T13:51:27.945329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = argparse.ArgumentParser(description='GCN, GCN-virtual, GIN, GIN-virtual')\n",
    "parser.add_argument('--device', type=int, default=3,\n",
    "                        help='which gpu to use if any (default: 0)')\n",
    "parser.add_argument('--gnn', type=str, default='sage',\n",
    "                        help='GNN gin, gin-virtual, or gcn, or gcn-virtual (default: gin-virtual), sage, pna, rgcn, gat')\n",
    "parser.add_argument('--drop_ratio', type=float, default=0.5,\n",
    "                        help='dropout ratio (default: 0.3)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                        help='number of GNN message passing layers (default: 5)')\n",
    "parser.add_argument('--emb_dim', type=int, default=100,\n",
    "                        help='dimensionality of hidden units in GNNs (default: 300)')\n",
    "parser.add_argument('--batch_size', type=int, default=1,\n",
    "                        help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=300,\n",
    "                        help='number of epochs to train (default: 300)')\n",
    "parser.add_argument('--num_workers', type=int, default=0,\n",
    "                        help='number of workers (default: 0)')\n",
    "parser.add_argument('--dataset', type=str, default=\"latncey_mnist_mix_nonuniform\",\n",
    "                        help='dataset name')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"sum\",\n",
    "                        help='sum, mean, max, attention')\n",
    "parser.add_argument('--save_dir', type=str, default=\"logs\",\n",
    "                        help='dir of saved models')\n",
    "parser.add_argument('--feature', type=str, default=\"full\",\n",
    "                        help='full feature or simple feature')\n",
    "parser.add_argument('--filename', type=str, default=\"train.tensor\",\n",
    "                        help='filename to output result (default: )')\n",
    "parser.add_argument('--train_log', type=str, default=\"train\",\n",
    "                        help='log file')\n",
    "parser.add_argument('--norm', type=str, default=1000,\n",
    "                        help='normalization factor')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# test module: dataset scale\n",
    "test_module = \"dataset\"\n",
    "test_dataset = \"latency_ap_cifar10dvs\"\n",
    "dataset = PygGraphPropPredDataset(test_dataset, root='./data')\n",
    "evaluator = Evaluator(test_dataset)\n",
    "if test_module == \"dataset\":\n",
    "    model_name = \"./saved_model/latency_dataset.pt\"\n",
    "    print('This will take some time.......')\n",
    "    for i in range(len(dataset.data.x)):\n",
    "        dataset.data.x[i][1:] = dataset.data.x[i][1:] * dataset.data.x[i][0] * 2\n",
    "    dataset.data.y = dataset.data.y/1000\n",
    "\n",
    "elif test_module == \"scale\":\n",
    "    model_name = \"./saved_model/latency_scale.pt\"\n",
    "    print('This will take some time.......')\n",
    "    for i in range(len(dataset.data.x)):\n",
    "        dataset.data.x[i][1:] = dataset.data.x[i][1:] * dataset.data.x[i][0] * 2\n",
    "    max_y = torch.max(dataset.data.y)\n",
    "    min_y = torch.min(dataset.data.y)\n",
    "    dataset.data.y = (dataset.data.y - min_y) / (max_y - min_y)*200\n",
    "\n",
    "split_idx = dataset.get_idx_split([0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.batch_size, shuffle=True,\n",
    "                              num_workers=args.num_workers)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.batch_size, shuffle=False,\n",
    "                              num_workers=args.num_workers)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=args.batch_size, shuffle=False,\n",
    "                             num_workers=args.num_workers)\n",
    "\n",
    "\n",
    "model = GNN(num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, net_type=args.gnn, graph_pooling=args.graph_pooling).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_name)['model_state_dict'])\n",
    "# train_perf, _, _ = eval_norm(model, device, test_loader, evaluator, min_y, max_y)\n",
    "train_perf, _, _ = eval(model, device, test_loader, evaluator)"
   ],
   "id": "325f013fc6682d0d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hy24/.conda/envs/ANPX/lib/python3.8/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/home/hy24/.conda/envs/ANPX/lib/python3.8/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/home/hy24/gnn-predictor/GNN/dataset_handcraft_pyg.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n",
      "/home/hy24/.conda/envs/ANPX/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/home/hy24/.conda/envs/ANPX/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This will take some time.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1689715/1439499710.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_name)['model_state_dict'])\n",
      "Iteration: 100%|██████████| 4500/4500 [00:08<00:00, 552.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape:[0.34566903]\n",
      "mse:[13.864375]\n",
      "smape:[0.24829891]\n",
      "r2:[0.90020126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2032c82c5931133d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
